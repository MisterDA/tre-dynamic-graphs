\documentclass[12pt,a4paper]{article}
\usepackage{polyglossia}
\setmainlanguage{french}
\usepackage{csquotes}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage[margin=2cm]{geometry}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{subfig}
\usepackage[backend=biber, style=numeric]{biblatex}
\bibliography{tre.bib}
\usepackage{hyperxmp}
\usepackage[colorlinks, citecolor=blue]{hyperref}
\usepackage{xcolor}
\usepackage{algorithm2e}
\usepackage{minted}
\usepackage[type={CC}, modifier={by-sa}, version={4.0}]{doclicense}

\title{Graphes Temporels ou Dynamiques}
\author{Antonin Décimo\\
Encadrants~: Michel Habib, Laurent Viennot}

\begin{document}
\maketitle
% \doclicenseThis{}
\section{Introduction}
Un graphe dynamique est un graphe qui évolue au cours du temps,
c'est-à-dire que des nœuds ou des arêtes peuvent apparaître ou
disparaître au cours du temps. On peut s'en servir pour modéliser des
réseaux informatiques, comme du calcul distribué ou de la téléphonie
mobile, ou bien encore des réseaux de transports routiers ou publics.

\begin{figure}[!h]
  \centering
  \subfloat[\(G_1\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.5, transform shape]
      \node[node] (e) {e};
      \node[node, above left=of e] (a) {a};
      \node[node, above right=of e] (b) {b};
      \node[node, below right=of e] (c) {c};
      \node[node, below left=of e] (d) {d};

      \path (a) edge (b);
      \path (e) edge (c);
    \end{tikzpicture}}
  \qquad
  \subfloat[\(G_2\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.5, transform shape]
      \node[node, draw=none] (e) {};
      \node[node, above left=of e] (a) {a};
      \node[node, above right=of e] (b) {b};
      \node[node, below right=of e] (c) {c};
      \node[node, below left=of e] (d) {d};

      \path (a) edge (b) edge [bend left=30] (c);
    \end{tikzpicture}}
  \qquad
  \subfloat[\(G_3\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.5, transform shape]
      \node[node] (e) {e};
      \node[node, above left=of e] (a) {a};
      \node[node, draw=none, above right=of e] (b) {};
      \node[node, below right=of e] (c) {c};
      \node[node, below left=of e] (d) {d};

      \path (c) edge (d) edge (e);
      \path (a) edge (e);
    \end{tikzpicture}}
  \qquad
  \subfloat[\(G_4\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.5, transform shape]
      \node[node] (e) {e};
      \node[node, above left=of e] (a) {a};
      \node[node, above right=of e] (b) {b};
      \node[node, below right=of e] (c) {c};
      \node[node, below left=of e] (d) {d};

      \path (b) edge (e) edge (c);
      \path (c) edge (d);
    \end{tikzpicture}}
  \caption{Graphe dynamique \(G = (G_1, G_2, G_3, G_4)\)}\label{fig:dyn_graph}
\end{figure}

Un graphe dynamique peut être représenté comme
dans~\ref{fig:dyn_graph}, où le temps est continu mais les événements
sont discrets.\\

Dans ce rapport, on rappelle quelques notions sur les graphes usuels,
puis on introduit les graphes dynamiques en comparant des modèles de
la littérature. On peut ensuite transposer les notions (chemins, …)
et les structures (sous-graphes, …) des graphes usuels aux graphes
dynamiques. On s'intéresse à un algorithme de calcul de l'arbre des
plus courts chemins dans un graphe dynamique, puis à deux articles de
recherche.

\subsection{Rappels}

\begin{description}
\item[Graphe] Les graphes (\textit{graphs}) sont des modèles abstraits
  constitués par la donnée de points, appelés nœuds (\textit{nodes})
  ou sommets (\textit{vertices}), et de liens entre ces points,
  appelés arêtes (\textit{edges}). Les arêtes comme les nœuds peuvent
  être étiquetées, le label représentant souvent le coût pour
  traverser l'élément. Un graphe est noté \(G = (V, E)\), où \(V\)
  est l'ensemble des sommets et \(E\) l'ensemble des arêtes.
\item[Non-orienté, orienté] Un graphe \(G = (V, E)\) est non-orienté si
  \(E\) est un ensemble de paires de sommets, orienté si \(E\) est un
  ensemble de couples de sommets.
\item[Chaîne, chemin] Une chaîne est une suite finie d'arêtes
  consécutives dans un graphe non-orienté. Un chemin est l'équivalent
  dans un graphe orienté.
\item[Degré] Le degré d'un sommet d'un graphe est le nombre de liens
  reliant ce sommet, noté \(\deg : V \to \mathbb{N}\). Dans le cas
  d'un graphe orienté, on parle de degré entrant, noté \(\deg^-\), et
  de degré sortant, noté \(\deg^+\).
\item[Connexité] (\textit{connectivity}) Un graphe non-orienté est
  connexe si pour tous \(u, v \in V\) il existe une chaîne de \(u\) à
  \(v\). Dans un graphe orienté, on parle de connexité forte s'il
  existe un chemin pour tous \(u, v \in V\).
\item[Graphe \(k\)-régulier] (\textit{\(k\)-regular}) Un graphe est
  \(k\)-régulier si tous ses sommets sont de degré \(k\).
\item[\(k\)-sommet-connexe] (\textit{\(k\)-vertex-connected}) Un
  graphe est \(k\)-sommet-connexe s'il possède plus de \(k\) sommets
  et s'il reste connexe après en avoir ôté moins de \(k\).
\item[Graphe expanseur] (\textit{expander graph}) Le taux d'expansion
  d'un graphe est une mesure de sa connectivité. Soit \(G = (V, E)\)
  un graphe, et \(W\) un sous-graphe de \(G\). La \textbf{frontière
    extérieure des sommets} (\textit{outer vertex boundary}) est
  l'ensemble des sommets de \(V \setminus W\) ayant au moins un voisin
  dans \(W\).
  \[\partial(W) = \left\{v \in V \setminus W \,\middle|\, \exists w
      \in W, (w, v) \in E\right\}\]

  On définit alors le \textbf{taux d'expansion des sommets}.
  \[h(G) = \min_{0 < |W| \leq n/2}\frac{|\partial(W)|}{|W|}\]
  \(G\) est un graphe \(c\)-expanseur si pour tout \(W \subset V\) tel
  que \(|W| \leq n / 2\), alors \(|\partial(W)| \geq c |W|\).
\end{description}

\section{Modèles de graphes dynamiques}

Les graphes dynamiques (\textit{dynamic graphs}) sont aussi appelés
graphes temporels (\textit{temporal graphs}), graphes de flux
(\textit{stream graphs}), réseaux dynamiques (\textit{dynamic
  networks}), graphes évolutifs (\(\textit{evolving graphs}\)),
graphes variants avec le temps (\(\textit{time-varying graphs}\)).

\subsection{Modèles sans latence}

\paragraph{Graphe de flux}\cite{latapy2017stream} (\textit{stream
  graph}) Un graphe de flux \(S = (T, V, W, E)\) est un ensemble fini
de nœuds \(V\), un ensemble d'instants \(T\), un ensemble de nœuds
temporels \(W \subseteq T \times V\) (un ensemble de nœuds indexés par
un temps), et un ensemble d'arêtes
\(E \subseteq T \times (V \otimes V)\) tel que si \((t, uv) \in E\)
alors \((t, u) \in W\) et \((t, v) \in W\) (si une arête existe à un
temps \(t\), alors les deux nœuds de l'arête existent aussi à ce
temps).

\paragraph{Flux de liens}\cite{latapy2017stream} (\textit{link
stream}) Si tous les nœuds du graphe de flux sont présents à chaque
instant, on parle de flux de liens.

\paragraph{Graphe évoluant}\cite{kuhn2011dynamic} (\textit{evolving
  graph}) Il s'agit d'un graphe dynamique \(G = (V, E)\), où \(V\) est
un ensemble de nœuds, et
\(E : \mathbb{N}^{+} \to \mathcal{P}(V \times V)\) est une fonction
attribuant à chaque tour \(r \in \mathbb{N}^{+}\) un ensemble d'arêtes
\(E(r)\) pour ce tour. Ici l'ensemble des nœuds ne varie pas.\\


Il n'y a pas de différence fondamentale entre les \textit{link
  streams} et les \textit{evolving graphs}, mais notons que les
\textit{stream graphs} et les \textit{link streams} se veulent plus
généraux en acceptant une définition plus large de la temporalité
(continue comme discrète), alors que les \textit{evolving graphs} sont
discrets.

\subsection{Modèles avec latence}

\paragraph{Time-Varying Graphs}\cite{casteigts2012time} (TVG) La présence
des entités est établie par intervalle de temps (discret ou
continu). On note \(\mathbb{T}\) le domaine temporel. Les auteurs
proposent de rajouter un label \(L\) sur chaque arête, et préfèrent
indiquer la présence d'arêtes et de nœuds par des fonctions. On a donc
\(G = (V, E \subseteq L \times V \otimes V, T \subseteq \mathbb{T},
\rho, \zeta)\), où~:
\begin{itemize}
\item \(\rho : E \times T \to \{\top, \bot\}\) est appelée fonction
  de présence et indique si une arête donnée est disponible à un temps
  donné.
\item \(\zeta : E \times T \to \mathbb{T}\) est appelée fonction de
  latence et indique le temps de parcours d'une arête donnée pour un
  départ à un temps donné (la latence d'une arête pouvant changer au
  cours du temps).
\end{itemize}

On peut à l'instar des arêtes étendre ce modèle aux nœuds du graphe,
avec \(\psi\) la fonction de présence et \(\varphi\) la fonction de
latence. En choisissant une fonction de latence constante à 1, on se
ramène à un modèle sans latence.

\section{Notions et Propriétés}

L'article~\cite{latapy2017stream} a pour but d'étendre les notions des
graphes usuels et des séries temporelles en les combinant pour donner
forme aux graphes de flux (\textit{stream graphs}),
\(S = (T, V, W, E)\). On retiendra quelques-unes de ces notions.

\paragraph{Couverture} (\textit{coverage}) La couverture de \(S\) est
la proportion de nœuds présents sur toutes les possibilités de
présence de nœuds.
\[cov(S) = \frac{|W|}{|T \times V|}\]

\paragraph{Nombre de nœuds, de liens} Chaque nœud (reps.\@ lien)
contribue proportionnellement à \(n = \frac{|W|}{|T|}\) (resp.\@
\(m = \frac{|E|}{|T|}\)) par son temps de présence dans \(S\)~:
\(v \in V\) vaut 1 s'il est toujours présent dans \(S\),
\((u, v) \in V \times V\) vaut 1 si elle est toujours présente dans
\(S\).

\paragraph{Voisinage et degré} Dans un graphe usuel \(G = (V, E)\), le
voisinage \(N(v)\) de \(v \in V\) est
\(N(v) = \{u \,|\, (u, v) \in E\}\), et \(\deg(v) = |N(v)|\). Dans un
graphe dynamique, le voisinage d'un nœud est défini par
\(N(v) = \{(t, u) \,|\, (t, uv) \in E\}\). La définition du degré est
identique. On peut restreindre la définition à un intervalle de temps
\(N_{[t_1, t_2]}(v) = \{u \,|\, (t, uv) \in E, t \in [t_1, t_2]\}\).\\

\paragraph{Uniformité} Notons \(T_u\) l'ensemble des instants où \(u\)
est présent. Si pour deux nœuds \(u\) et \(v\), \(|T_u| = |T_v|\),
alors on peut avoir \(T_u = T_v\), ou \(T_u \cap T_v = \emptyset\), ou
n'importe quelle autre situation. Pour capturer l'existence possible
de liens entre \(u\) et \(v\), on définit l'uniformité du graphe~:
\[\Cup(S) = \frac{\sum_{uv \in V \times V}|T_u \cap T_v|}{\sum_{uv \in
      V \times V}|T_u \cup T_v|}\]
Si \(\Cup(S) = 1\), on dit que \(S\) est uniforme. Tous les nœuds sont
présents aux mêmes instants.

\paragraph{Compacité} Soit \(S = (T, V, W, E)\) un graphe de flux,
définissons \(S' = (T', V', W, E)\) tel que
\(T' = [\min\{t \,|\, \exists (t, v) \in W\}, \max\{t \,|\, \exists
(t, v) \in W\}]\) (on restreint le graphe de la première apparition
dernière apparition de nœud), et
\(V' = \{v \,|\, \exists (t, v) \in W\}\) (on restreint le graphe aux
nœuds qui apparaissent au moins une fois). La compacité est définie
comme suit~:
\[c(S) = \frac{|W|}{|T' \times V'|} = cov(S')\]
Si \(c(S) = 1\), on dit que \(S\) est compact~: les temps de présence
de tous les nœuds sont le même intervalle de \(T\).\\

L'uniformité et la compacité d'un graphe de flux sont nécessairement
\(1\).\\

L'article~\cite{kuhn2010distributed} présente deux notions
intéressantes.

\paragraph{Connexité \(T\)‑intervalle}
Un graphe dynamique \(G = (V, E)\) est \(T\)‑intervalle connexe
(\textit{\(T\)‑interval connected}) pour \(T \geq 1\) si pour tout
\(r \in \mathbb{N}\), le graphe statique
\(G_{r,T} := \left(V, \bigcap_{i=r}^{r+T-1} E(r)\right)\) est
connexe. Le graphe est \(\infty\)‑intervalle connexe s'il existe un
graphe statique connexe \(G' = (V, E')\) tel que pour tous
\(r \in \mathbb{N}, E' \subseteq E(r)\)

\paragraph{Causalité de Lamport}
Soit un graphe dynamique \(G = (V, E, T)\), on peut définir un ordre
\(\rightarrow\) sur \((V, T)\), tel que
\((u, r) \rightarrow (v, r')\) ssi \((r' = r + 1)\) et
\(\{u, v\} \in E(r)\). L'\textbf{ordre causal} \(\rightsquigarrow\)
est défini comme clôture réflexive et transitive de \(\rightarrow\).

\subsection{Voyages et distances}

Les articles~\cite{xuan2003computing},~\cite{casteigts2012time},
et~\cite{latapy2017stream} définissent les concepts de chemins,
distances, et voyages dans les graphes dynamiques. Nous allons
considérer le modèle de~\cite{casteigts2012time}
(\(G = (V, E, T, \rho, \zeta)\)), plus complet.

\paragraph{Voyages, chemins} (\textit{journeys, paths}) Un voyage est
une séquence \(\mathcal{J} = \{(e_1, t_1), \dots, (e_k, t_k)\}\) telle
que \({e_1, \dots, e_k}\) est une marche dans le graphe,
\(\rho(e_i, t_i) = \top\), et \(t_{i+1} \geq t_i + \zeta(e_i, t_i)\)
pour tout \(i < k\). Selon l'application, on pourra supposer
\(\rho_{[t_i, t_i + \zeta(e_i, t_i)]}(e_i) = \top\), c'est-à-dire que
l'arête reste présente tandis qu'elle est traversée.

On notera \(arrival(\mathcal{J})\) et \(departure(\mathcal{J})\) les
temps de départ et d'arrivée du chemin
\(\mathcal{J}\). \(\mathcal{J}_{(u, v)}^*\) est l'ensemble des chemins
de \(u\) à \(v\).

Les auteurs ne proposent pas de définition tenant compte de la latence
des nœuds. Rappelons que si une arête est présente, alors chacun des
deux nœuds la constituant est aussi présent.

Dans les graphes dynamiques, les chemins sont asymétriques. Il est
impossible de revenir en arrière dans le temps. Il est parfois
possible de revenir sur un nœud à une date ultérieure.

\paragraph{Distance topologique} La distance topologique entre deux
nœuds dans un graphe est la longueur minimum (en nombre d'arêtes) des
chemins entre ces nœuds. On parle de \textbf{chemin le plus court}
(\textit{shortest path}).

\paragraph{Distance temporelle}
On dit qu'un chemin est \textbf{le plus rapide} (\textit{fastest
  path}) s'il est de durée (la somme des latences des nœuds et des
arêtes rencontrés) minimum.\\
Le temps pour atteindre \((t, v)\) depuis \(u\) au temps \(\alpha\)
est \(\mathcal{T}_{\alpha}(u, (t, v)) = \omega - \alpha\), où
\(\omega\) est la plus petite valeur pour laquelle il existe un chemin
de \((\alpha, u)\) à \((\omega, v)\). Un tel chemin est appelé
\textbf{premier chemin} (\textit{foremost path}).

\subsection{Structures}

En généralisant le langage habituel des graphes, on peut définir les
\textbf{sous-graphes dynamiques}, soit en considérant les sous-graphes
induits par des sous-ensembles de nœuds ou d'arêtes, soit en se
restreignant à un intervalle temporel.

Pour un graphe dynamique \(\mathcal{G} = (V, E, T, \rho, \zeta)\), on
appelle \textbf{graphe sous-jacent} \(G = (V, E)\) le graphe statique
dans lequel on oublie la dimension temporelle, et qui indique
seulement les nœuds en relation à un certain temps dans \(T\).

\subsection{Graphes dynamiques aléatoires}

Dans~\cite{casteigts2012time} et~\cite{kuhn2011dynamic}, les auteurs
construisent des graphes dynamiques aléatoires en posant que la
fonction de présence d'une arête \(\rho : E \times T \to {0, 1}\) suit
une loi de probabilité. On peut imaginer des graphes dynamiques
suivant des chaînes de Markov, où une arête apparaît au tour suivant
avec une probabilité \(p\) et disparaît avec une probabilité \(q\),
indépendamment des autres arêtes. Si \(q = 1 - p\), chaque graphe
statique est un graphe d'Erdős-Rényi.

\section{Algorithmes}

\subsection{Flot maximum}

\paragraph{Flot} On considère un graphe orienté \(G = (V, E)\) et deux
sommets \(s, t \in V\). Les arcs sont munis de capacités
\(c : E \to \mathbb{R}^{+}\).  Un flot sur \(G\) est un vecteur
\(\phi\) indexé par \(E\) qui vérifie les lois de Kirchhoff~:
\begin{itemize}
\item \(\forall (u, v) \in E, 0 \leq \phi(u, v) \leq c(u, v)\)
\item \(\forall v \in V, \sum_{(u, v) \in E} \phi(u, v) = \sum_{(v, w)
    \in E} \phi(v, w)\)
\end{itemize}
On cherche un flot qui maximise \(\phi(t, s)\).

\begin{figure}[!h]
  \centering
  \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
    scale=0.5, transform shape]
    \node[node] (s) {s};
    \node[node, above right=of s] (a) {};
    \node[node, below=of a] (b) {};
    \node[node, right=of a] (c) {};
    \node[node, right=of b] (d) {};
    \node[node, below right=of c] (t) {t};

    \draw[->] (s) -- (a) node [midway, above] {6};
    \draw[->] (s) -- (b) node [midway, above] {9};
    \draw[->] (a) -- (c) node [midway, above] {5};
    \draw[->] (a) -- (d) node [midway, above] {4};
    \draw[->] (b) -- (d) node [midway, above] {6};
    \draw[->] (c) -- (t) node [midway, above] {2};
    \draw[->] (d) -- (t) node [midway, above] {8};
    \draw[->, dashed] (t) to[bend left=50] node[above] {?} (s);
  \end{tikzpicture}
  \caption{Flot}
\end{figure}

Les algorithmes partent du flot nul, et utilisent une suite de chemins
augmentant. Entre deux étapes, le graphe change. On peut donc voir les
algorithmes de flot maximum comme les algorithmes de graphes
dynamiques.

\subsection{Diamètre dynamique}
(\textit{dynamic diameter}, \textit{flooding time}) Soit
\(G = (V, E)\) un graphe dynamique et \(u \in V\). Si
\(\forall v \in V, (u, t) \rightsquigarrow (v, t' + D)\), alors \(D\)
est le diamètre dynamique du graphe. Il faut comprendre que si \(u\)
envoie un message au temps \(t\), alors le message mettra au maximum
\(D\) tours pour atteindre tous les nœuds du graphe. Le problème est
de déterminer le diamètre dynamique du graphe.

\subsection{Plus court chemin (\textit{shortest path})}

\paragraph{Préfixe}
On considère le problème de calculer les chemins les plus courts en
nombre de sauts (\textit{hop-count}) d'un nœud \(u\) pour chacun des
autres nœuds du graphe. Dans un graphe usuel, cela revient à exécuter
le parcours en largeur (\textit{BFS}), ou l'algorithme de Dijkstra si
toutes les arêtes sont de poids \(1\).

L'algorithme usuel est basé sur l'observation qu'un préfixe d'un plus
court chemin est plus court chemin lui-même. Malheureusement, dans les
graphes dynamique cette propriété n'est plus
vraie. Dans~\ref{shortest_path_prefix}, le plus court chemin de \(s\)
à \(t\) est bien
\(\mathcal{J} = s \rightarrow a \rightarrow b \rightarrow t\), mais le
préfixe \(\mathcal{J'} = s \rightarrow a \rightarrow b\) de
\(\mathcal{J}\) n'est pas le plus court chemin de \(s\) à \(b\), c'est
\(s \rightarrow b\), disponible au temps \(1\).

\begin{figure}[!h]
  \centering
  \subfloat[\(G_0\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.5, transform shape]
      \node[node] (s) {s};
      \node[node, right=of s] (a) {a};
      \node[node, right=of a] (b) {b};
      \node[node, right=of b] (t) {t};

      \path[->] (s) edge (a);
      \path[->] (a) edge (b);
      \path[->] (b) edge (t);
    \end{tikzpicture}}
  \qquad
  \subfloat[\(G_1\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.5, transform shape]
      \node[node] (s) {s};
      \node[node, draw=none, right=of s] (a) {};
      \node[node, right=of a] (b) {b};

      \path[->] (s) edge (b);
    \end{tikzpicture}}
  \caption{Le préfixe d'un plus court chemin n'est pas le plus court
    chemin}\label{shortest_path_prefix}
\end{figure}

Les auteurs de~\cite{xuan2003computing} proposent une autre propriété
de préfixe. Si la dernière arête \((v, w)\) d'un plus court chemin
entre \(u\) et \(w\) débute au temps \(t\), alors le chemin préfixe
(de \(u\) à \(v\)) est plus court que tous les autres
chemins de \(u\) à \(v\) finissant avant \(t\).\\

\paragraph{Modèle}
L'algorithme~\ref{alg:shortest_path}, présenté
dans~\cite{xuan2003computing}, calcule les plus courts chemins dans un
graphe dynamique. Les auteurs font plusieurs suppositions~:
\begin{itemize}
\item On ne peut pas s'engager dans une arête si elle disparaît avant
  de l'avoir traversée. Si l'arête \(e\) existe sur \([t_1, t_2]\), et
  qu'on s'engage dans l'arête au temps \(t \in [t_1, t_2]\), alors
  \(t + traversal(e) \leq t_2\).
\item Si l'arête \(e = (u, v)\) existe sur \([t_1, t_2]\), alors \(u\)
  et \(v\) existent sur \([t_1, t_2]\).
\item Il n'existe qu'une seule arête entre deux nœuds (pas de
  multigraphe).
\item La latence d'une arête ne varie pas au cours du temps.
\end{itemize}

\paragraph{Condition d'arrêt}
Pour un nœud \(u\) présent au temps \(t\), la fonction
\(neighbours : V \times \mathbb{T} \to \mathcal{P}(V \times
\mathbb{T})\) renvoie \((v, t')\) si \(v\) est un voisin accessible de
\(u\) au temps le plus tôt \(t' \geq t\).\\

L'algorithme présentait comme condition de boucle principale~:
\begin{center}
  \verb|while| \(\exists w \in V_G\) \verb|tel que| \(location(w)\)
  \verb|n'est pas définie|.
\end{center}
Cette condition n'est pas très pertinente; en effet si un nœud n'est
pas atteignable depuis \((s, 0)\), alors ce nœud ne sera jamais marqué
par \(location\) et l'algorithme ne termine pas. Il existe une
meilleure condition d'arrêt~: si aucun nœud n'a été inséré à la
profondeur \(d\), alors il n'existe pas de plus court chemin de
longueur au moins \(d\). L'algorithme s'arrête dès que cette condition
est atteinte.\\

\begin{algorithm}[H]
  \DontPrintSemicolon{}
  \KwIn{Un graphe dynamique \(G\), un nœud \(s \in V_G\)}
  \KwData{L'arbre \(T\) des paires \((u, t) \in V_G \times
    \mathbb{R}^*_+\); un entier \(d\); un tableau \(earliest : V_G \to
    \mathbb{R}^*_+\)}
  \KwResult{L'arbre des plus courts chemins \(T\), un tableau
    \(location : V_G \to T\)}
  \(T \leftarrow \{(s, 0)\}\)\;
  \(earliest(s) \leftarrow 0\)\;
  \(\forall u \neq s, earliest(u) \leftarrow \infty\)\;
  \(d \leftarrow 1\)\;
  \(location(s) \leftarrow (s, 0)\)\;
  \(run \leftarrow \top\)\;
  \While{\(run = \top\)}{
    \(run \leftarrow \bot\)\;
    \ForEach{\((u, t) \in T\) à la profondeur \(d\)}{
      \ForEach{\((v, t') \in neighbours(u, t)\)}{
        \If{\(location(v)\) n'est pas définie}{
          \(location(v) \leftarrow (v, t')\)\;
        }
        \If{\(t' < earliest(v)\)}{
          \(earliest(v) \leftarrow t'\)\;
          \((v, t')\) est enfant de \((u, t)\) dans \(T\)\;
          \(run \leftarrow \top\)\;
        }
      }
    }
    \(d \leftarrow d + 1\)\;
  }
  \caption{Arbre des plus courts chemins\label{alg:shortest_path}}
\end{algorithm}

Une fois que l'arbre a été calculé, retrouver le chemin de \(s\) à
n'importe quel sommet \(u\) est aisé~: \(location(u)\) donne la paire
\((u, t)\) correspondante dans l'arbre. On retrouve le chemin en
cherchant le parent de \((u, t)\) dans l'arbre \(T\).

\paragraph{Correction sur les \textit{Link streams}} Supposons que le
graphe est un \textit{link stream}, c'est-à-dire que l'ensemble des
nœuds est invariant. Tous les nœuds sont présents pendant toute
l'existence du graphe, et seules les arêtes changent. L'invariant est
la propriété du préfixe~: si \(\mathcal{J}_{u, w}\) est un plus court
chemin, et que sa dernière arête est \((v, w)\) débutant au temps
\(t\), alors \(\mathcal{J}_{u, v}\) est le plus court de tous les
chemins de \(u\) à \(v\) finissant avant \(t\).

\subparagraph{Initialisation} \(T\) est initialisé à \((s, 0)\). Si le
graphe est réduit à \(s\), \(T\) est bien un arbre de plus courts
chemins. \(location(v)\) pointe vers le plus court chemin
\(s \xrightarrow{0} s\).

\subparagraph{Récurrence} Soit \((u, t_u)\) un sommet accessible
depuis \((s, 0)\) en \(d\) sauts. \((u, t_u)\) est dans l'arbre \(T\)
à la profondeur \(d\). Soit \((v, t_v)\) un voisin de \((u, t_u)\)
accessible au plus tôt en \(t_v\). \((s, 0) \xrightarrow{d} (u, t_u)\)
est le plus court de tous les chemins de \(s\) à \(u\) finissant avant
\(t_v\). \\

Supposons que \((s, 0) \xrightarrow{d} (u, t_u) \rightarrow (v, t_v)\)
soit un plus court chemin. Il y a alors deux possibilités.
\begin{itemize}
\item C'est la première fois que l'on rencontre \(v\) à la profondeur
  \(d + 1\). \(location(v)\) n'est pas définie, car sinon \((v, \_)\)
  serait déjà dans l'arbre à une profondeur \(< d\). On définit donc
  \(location(v) := (v, t_v)\). De même, \(earliest(v) =
  \infty\). Alors \(earliest(v) := t_v\), et \((v, t_v)\) est ajouté
  dans l'arbre des plus courts chemins avec comme parent \((u, t_u)\).
\item On a déjà rencontré \(v\) à la profondeur \(d +
  1\). \(location(v)\) est donc définie. Rappelons que les nœuds sont
  toujours présents, donc
  \(\forall u \in V, \forall t' > t \in T, neighbours(u, t') \subseteq
  neighbours(u, t)\). Si \(t_v < earliest(v)\), alors \((v, t_v)\)
  capture plus de voisins que \((v, earliest(v))\) et doit être ajouté
  à l'arbre des plus courts chemins avec comme parent \(u, t_u\). On
  met à jour \(earliest(v) := t_v\). Il n'y a pas besoin de mettre à
  jour \(location(v)\) qui pointe déjà vers un plus court chemin
  \(s \xrightarrow{d+1} v\). Si \(t_v \geq earliest(v)\) alors
  \((v, earliest(v))\) capture au moins autant de voisins que
  \((v, t_v)\), et \((v, t_v)\) n'est pas ajouté à \(T\).
\end{itemize}
À la fin de cette boucle, \((v, earliest(v))\) est présent dans
l'arbre des plus courts chemins à la profondeur \(d + 1\) avec comme
parent \((u, t_u)\), \(location(v)\) pointe vers un plus court chemin
\(s \xrightarrow{d+1} v\), et \(earliest(v)\) est le temps le plus tôt
auquel on puisse accéder à \(v\). L'invariant est conservé.\\

Supposons que \((s, 0) \xrightarrow{d} (u, t_u) \rightarrow (v, t_v)\)
ne soit pas un plus court chemin \(s \xrightarrow{d+1} v\). Par
conséquent, il existe un plus court chemin
\(\mathcal{J} = s \xrightarrow{d'} v\) avec \(d' \leq d\). Par
hypothèse, \(\mathcal{J}\) est déjà dans \(T\), donc \(location(v)\)
pointe sur \(\mathcal{J}\). Deux cas se présentent~:
\begin{itemize}
\item Si \(t_v < earliest(v)\), alors
  \(neighbours(v, earliest(v)) \subseteq neighbours(v, t_v)\). Il faut
  donc ajouter \((v, t_v)\) à \(T\) avec comme parent \(u, t_u\), mais
  sans mettre à jour \(location(v)\). Ainsi, \(location(v)\)
  continuera de pointer vers un plus court chemin
  \(s \xrightarrow{d'} v\). S'il existe un voisin \((w, t)\) de
  \((v, t_v)\) accessible seulement sur \([t_v, earliest(v)[\), alors
  l'invariant est vérifié pour ce voisin. En effet le chemin
  \((s, 0) \xrightarrow{d+1} (v, t_v)\) est le plus court des chemins
  de \(s\) à \(v\) se terminant avant \(t\). On met à jour
  \(earliest(v) := t_v\).
\item Si \(t_v \geq earliest(v)\), alors \(neighbours(v, t_v)
  \subseteq neighbours(v, earliest(v))\). Il n'y a donc rien à faire
  de \((v, t_v)\).
\end{itemize}
À la fin de cette boucle, l'invariant est correct pour tous les nœuds
de l'arbre.\\

La terminaison de l'algorithme est évidente, l'algorithme est donc
correct sur les \textit{link streams}.

\paragraph{Correction sur les \textit{stream graphs}} Dans le cas d'un
\textit{stream graph} (on attribue une fonction de présence aux
nœuds), l'algorithme n'est plus correct. Observons que \(neighbours\)
doit vérifier la propriété suivante~: si \(u\) est présent sur
\([t_1, t_2]\) puis \([t_3, t_4]\), et soit \(t \in [t_1, t_2]\),
alors \(neighbours(u, t)\) ne renvoie que les voisins de \(u\)
accessibles en \([t_1, t_2]\) et pas \([t_3, t_4]\). Si \(neighbours\)
ne vérifie pas cette propriété, alors on pourrait stationner sur \(u\)
à partir de \(t_1\) pour accéder aux voisins disponibles en
\([t_3, t_4]\), bien que \(u\) disparaisse entre \(t_2\) et \(t_3\).

Considérons le graphe~\ref{fig:graph_bug}, où la latence des arêtes
est \(0\). Il y a \(4\) étapes. L'algorithme ne pourra pas découvrir
le nœud \(f\), pourtant accessible au temps 3 par
\(s \rightarrow a \rightarrow b \rightarrow c \rightarrow e
\rightarrow f\), en stationnant sur \(c\) aux temps \(1\) et \(2\).

\begin{figure}[!h]
  \centering
  \subfloat[\(G_0\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.4, transform shape]
      \node[node] (s) {s};
      \node[node, above right=of s] (a) {a};
      \node[node, right=of a] (b) {b};
      \node[node, right=of b] (c) {c};
      \node[node, below right=of s] (d) {d};

      \path[->] (s) edge (a) edge (d);
      \path[->] (a) edge (b);
      \path[->] (b) edge (c);
    \end{tikzpicture}}
  \quad
  \subfloat[\(G_1\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.4, transform shape]
      \node[node, draw=none] (s) {};
      \node[node, draw=none, above right=of s] (a) {};
      \node[node, draw=none, right=of a] (b) {};
      \node[node, right=of b] (c) {c};
      \node[node, below right=of s] (d) {d};
      \node[node, below right=of c] (e) {e};

      \path[->] (d) edge (e);
    \end{tikzpicture}}
  \quad
  \subfloat[\(G_2\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.4, transform shape]
      \node[node, draw=none] (s) {};
      \node[node, draw=none, above right=of s] (a) {};
      \node[node, draw=none, right=of a] (b) {};
      \node[node, right=of b] (c) {c};
      \node[node, draw=none, below right=of s] (d) {};
    \end{tikzpicture}}
  \quad
  \subfloat[\(G_3\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.4, transform shape]
      \node[node, draw=none] (s) {};
      \node[node, draw=none, above right=of s] (a) {};
      \node[node, draw=none, right=of a] (b) {};
      \node[node, right=of b] (c) {c};
      \node[node, draw=none, below right=of s] (d) {};
      \node[node, below right=of c] (e) {e};
      \node[node, right=of e] (f) {f};

      \path[->] (c) edge (e);
      \path[->] (e) edge (f);
    \end{tikzpicture}}
  \caption{Graphe dynamique
    \(G = (G_0, G_1, G_2, G_3)\)}\label{fig:graph_bug}
\end{figure}

Il y a un problème lors de la construction de l'arbre des plus courts
chemins~\ref{fig:tree_bug}. Dans \(T_2\), on découvre pour la première
fois \(e\) que l'on marque \(location(e) = (e, 1)\) et
\(earliest(e) = 1\). Dans \(T_3\), en examinant \((c, 0)\) on va
découvrir le nœud \((e, 3)\). Or \(earliest(e) = 1 < 3\), donc on
n'entre pas dans le deuxième \verb|if| et \((e, 3)\) n'est pas
introduit dans l'arbre. Par conséquent, \(f\) n'est jamais découvert.

\begin{figure}[!h]
  \centering
  \subfloat[\(T_0\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.4, transform shape]
      \node[node] (s) {\((s, 0)\)};
      \node[node, draw=none, above right=of s] (a) {};
      \node[node, draw=none, below right=of s] (d) {};
    \end{tikzpicture}}
  \quad
  \subfloat[\(T_1\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.4, transform shape]
      \node[node] (s) {\((s, 0)\)};
      \node[node, above right=of s] (a) {\((a, 0)\)};
      \node[node, below right=of s] (d) {\((d, 0)\)};

      \path[->] (a) edge (s);
      \path[->] (d) edge (s);
    \end{tikzpicture}}
  \quad
  \subfloat[\(T_2\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.4, transform shape]
      \node[node] (s) {\((s, 0)\)};
      \node[node, above right=of s] (a) {\((a, 0)\)};
      \node[node, below right=of s] (d) {\((d, 0)\)};
      \node[node, right=of a] (b) {\((b, 0)\)};
      \node[node, right=of d] (e) {\((e, 1)\)};

      \path[->] (a) edge (s);
      \path[->] (d) edge (s);
      \path[->] (b) edge (a);
      \path[->] (e) edge (d);
    \end{tikzpicture}}
  \quad
  \subfloat[\(T_3\)]{
    \begin{tikzpicture}[node/.style={circle, draw, minimum size=1cm]},
      scale=0.4, transform shape]
      \node[node] (s) {\((s, 0)\)};
      \node[node, above right=of s] (a) {\((a, 0)\)};
      \node[node, below right=of s] (d) {\((d, 0)\)};
      \node[node, right=of a] (b) {\((b, 0)\)};
      \node[node, right=of d] (e) {\((e, 1)\)};
      \node[node, right=of b] (c) {\((c, 0)\)};

      \path[->] (a) edge (s);
      \path[->] (d) edge (s);
      \path[->] (b) edge (a);
      \path[->] (e) edge (d);
      \path[->] (c) edge (b);
    \end{tikzpicture}}
  \caption{Arbre des plus courts chemins de \(G\)}\label{fig:tree_bug}
\end{figure}

L'exemple donné vérifie bien les conditions de la propriété du
préfixe~;
\(\mathcal{J}_1 = s \rightarrow a \rightarrow b \rightarrow c
\rightarrow e \rightarrow f\) est bien le plus court chemin de \(s\) à
\(f\), mais le chemin préfixe
\(\mathcal{J}'_1 = s \rightarrow a \rightarrow b \rightarrow c
\rightarrow e\) n'est pas le plus court chemin de \(s\) à \(e\), c'est
\(\mathcal{J}_2 = s \rightarrow d \rightarrow e\). Notons que
\(e \rightarrow f\) démarre au temps \(t = 3\), et \(\mathcal{J}_2\)
finit en \(1\), donc avant \(t\).

\paragraph{Implémentation}
Une implémentation de cet algorithme réalisée en OCaml est disponible
à l'adresse
\url{https://gist.github.com/MisterDA/6dfb9740ce992ffc2890de83e968eb49}. Les
contraintes de l'algorithme ont été conservées.

Le graphe est présenté sous forme de liste
d'adjacence~\ref{listing:datastruct}. Chaque nœud contient ses temps
de présence, la liste de ses voisins et les temps où chacun d'entre
eux est accessible, ainsi que la latence de l'arc. Les nœuds sont
identifiés de manière unique par leur nom. On suppose que les données
sont valides (les intervalles de temps ne se recoupent pas, …)  et
triées.

\begin{listing}[ht]
  \begin{minted}{ocaml}
type time = float
type time_interval = time * time (* start * finish *)

type node = {
    name : string;
    node_schedule : time_interval list;
    neighbours : neighbour list;
  }
and neighbour = {
    node : node;
    arc_schedule : time_interval list;
    traversal : time;
  }
type graph = node list
  \end{minted}
  \caption{Structure de données de graphe
    dynamique}\label{listing:datastruct}
\end{listing}

Pour le graphe~\ref{fig:dyn_graph}, \(shortest\_path(a, d)\) donne
\mint{text}|a 0.000000 -> c 1.000000 -> d 2.000000| et pour le
graphe~\ref{fig:graph_bug}, \(shortest\_path(s, f)\) donne
\mint{text}|Fatal error: exception Failure("location (f) was not
set")|

\paragraph{Optimisation de l'algorithme} On a vu que dans le cas des
\(\textit{link streams}\),
\(\forall u \in V, \forall t' > t \in T, neighbours(u, t') \subseteq
neighbours(u, t)\). Si on observe d'abord les voisins de \((u, t')\),
puis qu'on découvre \((u, t)\), il est inutile d'observer deux fois
\(neighbours(u, t) \setminus neighbours(u, t')\).
\textcolor{red}{C'était bien ça l'optimisation~?}

\paragraph{Complexité} \textcolor{red}{FIXME:\@ complexité de l'algo.}

\paragraph{Révision de l'algorithme}
Nous proposons une révision à la propriété de préfixe~: il faut que
\(\mathcal{J}' = u \rightarrow^* v\) soit plus court que tous les
autres chemins se finissant avant \(t\), et que \(w\) soit voisin de
\((v, arrival(\mathcal{J}'))\).

L'algorithme deviendrait~:
\begin{center}
  \verb|if| \(t' < earliest(v)\) \verb|or|
  \(neighbours(v, t') \neq neighbours(v, earliest(v))\) \verb|then|
\end{center}

\textcolor{red}{FIXME:\@ nouvelle preuve de l'algo, je suis à peu près
  convaincu du préfixe, mais pas de la nouvelle condition.}

\section{Notes de Lecture}
\subsection{Time-varying graphs and dynamic
  networks~\cite{casteigts2012time}}
Les auteurs identifient trois champs d'applications possibles des
graphes dynamiques.
\begin{description}
\item[Delay-Tolerant Networks]~\cite{fall2007delay} La caractéristique
  principale de ces réseaux est la possibilité de ne pas être connexe
  à un moment donné. Les chemins généralement disponibles au cours du
  temps, et la diffusion ou le routage sont réalisables grâce au
  mécanisme de \textit{store-carry-forward} (un exemple est celui du
  courrier électronique).
\item[Opportunistic-Mobility Networks] Ce sont aussi des DNT, avec la
  différence que les nœuds sont mobiles. Il existe des réseaux de
  taxis et de bus équipés de routeurs.
\item[Real-World Complex Networks] Dans cette catégorie tombent tous
  les autres types de réseaux (réseaux sociaux, transports, …),
  unifiés par l'utilisation d'un même formalisme et de concepts comme
  les chemins, la distance, la connexité, en fonction de l'évolution
  du réseau.
\end{description}

Les auteurs définissent ensuite les \textit{time-varying graphs}, un
modèle de graphe dynamique avec latence. Ils se contente dans le reste
de l'article d'évoquer la latence sur les arêtes. La latence sur un
nœud peut être imaginée comme un temps de calcul, ou de transfert.

Les auteurs décrivent le graphe sous-jacent d'un graphe dynamique,
puis développent la notion de point de vue par rapport à l'évolution
du graphe. Pour une arête, l'évolution se cantonne à une variation de
disponibilité (l'arête est-elle présente ou non) et de latence. Pour
un nœud, il s'agit de changements dans le voisinage. Enfin, par
rapport au graphe, l'évolution est considérée comme un séquence de
graphes statiques \(G_1, G_2, \dots\), où chaque graphe statique est
défini par un événement topologique (et \(G_i \neq G_{i+1}\)), ou bien
par un instantané au temps \(t = i\) (et on peut avoir
\(G_i = G_{i+1}\)). On parle d'\textit{evolving graphs} pour
représenter un graphe dynamique par une séquence de graphes statiques.

Les auteurs rappellent les définitions de sous-graphe d'un graphe
dynamique, de chemin, de distance, et d'autres concepts.

La contribution principale de l'article est la classification des TVG
selon des propriétés. En voici quelques-unes~:

\begin{itemize}
\item \(\exists u \in V : \forall v \in V, u \rightsquigarrow v\). On
  peut diffuser dans tout le graphe à partir d'un nœud.
\item \(\exists u \in V : \forall v \in V, v \rightsquigarrow u\). Il
  existe un nœud qui peut être atteint par tous les autres. C'est une
  condition nécessaire pour un calcul réparti sur tout le réseau, avec
  un nœud de sortie.
\item
  \(\forall u, v \in V, \exists \mathcal{J}_1 \in
  \mathcal{J}^*_{(u,v)}, \exists \mathcal{J}_1 \in
  \mathcal{J}^*_{(v,u)}~: arrival(\mathcal{J}_1) \leq
  departure(\mathcal{J}_2)\). (\textit{round connectivity}) Chaque
  nœud peut joindre tous les autres, et peut être joint
  ultérieurement. Cette condition peut être requise pour s'assurer
  explicitement que certains algorithmes terminent.
\item
  \(\forall e \in E, \forall t \in T, \forall k \in \mathbb{N},
  \rho(e, t) = \rho(e, t + kp)\), pour un \(p \in T\), et \(G\) est
  connexe. Cette propriété de périodicité peut être retrouvée dans les
  réseaux de transports, ou les DNT.\@ On peut s'en servir pour
  réutiliser des calculs de chemins, modulo \(p\).
\end{itemize}

Sont présentés les phénomènes de \textit{small world}, où la distance
(en termes de sauts) entre deux nœuds croît logarithmiquement par
rapport au nombre de nœuds du graphe; et la \textit{fairness and
  balance}, l'écart-type de l'excentricité temporelle des nœuds.\\

En conclusion, les auteurs remarquent que peu de problèmes autour des
graphes dynamiques ont été étudiés, mais si une situation peut être
modélisée par un graphe dynamique, alors on peut se servir du
formalisme et des phénomènes présentés pour l'étudier. Une situation
intéressante est celle où on modélise les interactions d'un groupe
social par un graphe dynamique et de on tente de minimiser
l'éloignement temporel moyen afin d'accélérer les échanges.

\subsection{Dynamic Netwoks: Models and
  Algorithms~\cite{kuhn2011dynamic}}

Il s'agit essentiellement d'une revue de la littérature, mais qui
présente néanmoins deux résultats. Tout d'abord, les auteurs
définissent leur cadre d'étude~: des réseaux dynamiques dans lesquels
les changements sont incessants, incontrôlables. Les algorithmes
doivent terminer.

Le modèle utilisé est celui des \textit{evolving graphs}, le temps est
discrétisé. La fonction de présence des arêtes est dynamique, et
déterminée par un \textbf{modèle d'adversaire}. On a
l'\textit{adaptative worst-case adversary} qui génère le graphe à la
volée d'après l'évolution passée du graphe; l'\textit{oblivious
  worst-case adversary} impose un graphe pré-déterminé; et le
\textit{random-graph adversary}, lequel n'est pas vraiment un
adversaire mais une loi de probabilité déterminant l'évolution du
graphe.

\paragraph{Croissance de nœuds} Les auteurs définissent la
\textit{vertex growth function} \(g : \mathbb{N} \to \mathbb{N}\), qui
généralise la notion de graphe expanseur. Un graphe (statique)
\(G = (V, E)\) a une croissance de nœuds \(g\) si pour tout ensemble
de nœuds \(S \subset V\) de taille \(s = |S| \leq |V|/2\), l'ensemble
des voisins
\(N(S) := \{v \in V \setminus S \,|\, \exists u \in S : (u, v) \in
E\}\) est de taille au moins \(|N(S)| \geq g(|S|)\).

Par exemple, si \(G\) est connexe, sa croissance est au moins \(1\);
s'il est \(k\)-connexe, sa croissance est au moins \(g(s) = k\); si
\(G\) est un \(\alpha\)-expanseur, alors \(g(s) = \alpha s\).

On note \(g^{(f)}\) l'itérée après \(f\) tours, avec
\(g^{(0)}(s) = s\), et pour \(f > 0\),
\(g^{(f)}(s) = g^{(f-1)}(s) + g(g^{(f-1)}(s))\).

\textcolor{red}{FIXME:\@ clarifier, exemple}.\\

Si chaque graphe statique est un expanseur, le diamètre dynamique est
\(O(\log n)\); s'ils sont \(k\)-connexe, le diamètre est \(O(n/k)\).
\textcolor{red}{FIXME:\@ quote, preuve}.

\paragraph{Lemme} Soit \(G = (V, E)\) un graphe dynamique tel que pour
chaque tour \(r\), le graphe statique \(G(r)\) est \(g\)-croissant. Le
diamètre dynamique de \(G\) est au plus \(2d\), où \(d\) est le plus
petit entier tel que \(g^{(d)}(1) > |V|/2\).\\

Les auteurs considèrent ensuite le problème de la synchronisation
d'horloges dans un réseau. Cela peut être utile pour passer
discrétiser le temps, par exemple pour effectuer une action tous les
\(t\) instants.

Les auteurs prouvent les bornes inférieure et supérieure du
diamètre dynamique pour les graphes de Markov.\\

Afin de pouvoir résoudre divers problèmes dans les graphes dynamiques
(par exemple compter le nombres de nœuds, en supposant qu'il ne varie
pas), les auteurs explorent un problème intermédiaire, le
\(k\)-comité.

\section{Conclusion}
\textcolor{red}{FIXME:\@ do something}

\printbibliography{}

\end{document}
